{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50f9c6b",
   "metadata": {},
   "source": [
    "# Test_pretrained_ke-t5-small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c8dcb",
   "metadata": {},
   "source": [
    "## git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e850b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git config --global user.name candym1\n",
    "# !git config --global user.email tmxk5283@gmail.com\n",
    "# !git clone https://github.com/seuyon0101/saturi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfbb75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd saturi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece2a95",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc7c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ed1ce",
   "metadata": {},
   "source": [
    "## Test data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cc2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_path = os.getenv('HOME')+\"/korean-english-park.train.ko\"\n",
    "eng_path = os.getenv('HOME')+\"/korean-english-park.train.en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e9dabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
      ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
      ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
     ]
    }
   ],
   "source": [
    "with open(kor_path, \"r\") as f:\n",
    "    kor = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(kor))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in kor[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9033223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> Much of personal computing is about \"can you top this?\"\n",
      ">> Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.\n",
      ">> “Guard robots are used privately and professionally to detect intruders or fire,” Karlsson said.\n",
      ">> Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",
      ">> Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.\n"
     ]
    }
   ],
   "source": [
    "with open(eng_path, \"r\") as f:\n",
    "    eng = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(eng))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in eng[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "966afe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = []\n",
    "for i in range(len(kor)):\n",
    "    set_corpus = []\n",
    "    raw_sen = kor[i] + ' <TSL> ' + eng[i]\n",
    "    set_corpus.append(raw_sen)\n",
    "    for t in range(len(set_corpus)):\n",
    "        set_corpus = list(set(set_corpus))\n",
    "        for s in set_corpus:\n",
    "            result = \"\"\n",
    "            result += s\n",
    "            cleaned_corpus.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba00da03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"그러나 이것은 또한 책상도 필요로 하지 않는다. <TSL> Like all optical mice, But it also doesn't need a desk.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62bff3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence_ko(sentence, s_token=False, e_token=False):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎ가-힣a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a02fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence_en(sentence, s_token=False, e_token=False):\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a701eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\" <TSL> Much of personal computing is about \"can you top this?\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abe8e844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean: 개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?\n",
      "English: <start> much of personal computing is about can you top this ? <end>\n"
     ]
    }
   ],
   "source": [
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "num_examples = 30000\n",
    "\n",
    "for z in range(num_examples):\n",
    "    ko, en = cleaned_corpus[z].split(\" <TSL> \")\n",
    "    \n",
    "    enc_corpus.append(preprocess_sentence_ko(ko))\n",
    "    dec_corpus.append(preprocess_sentence_en(en, s_token=True, e_token=True))\n",
    "    \n",
    "print(\"Korean:\", enc_corpus[0])\n",
    "print(\"English:\", dec_corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccfedee",
   "metadata": {},
   "source": [
    "### DataFreame 으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e51c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(enc_corpus, dec_corpus))\n",
    "df.columns = ['input', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1696ba3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?</td>\n",
       "      <td>&lt;start&gt; much of personal computing is about ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...</td>\n",
       "      <td>&lt;start&gt; so a mention a few weeks ago about a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그러나 이것은 또한 책상도 필요로 하지 않는다 .</td>\n",
       "      <td>&lt;start&gt; like all optical mice , but it also do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. 달러하는 이 최첨단 무선 광마우스는 허공에서 팔목 , 팔 , 그외에 어떤 부분이...</td>\n",
       "      <td>&lt;start&gt; uses gyroscopic sensors to control the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정보 관리들은 동남 아시아에서의 선박들에 대한 많은 테러 계획들이 실패로 돌아갔음을...</td>\n",
       "      <td>&lt;start&gt; intelligence officials have revealed a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0                개인용 컴퓨터 사용의 상당 부분은 이것보다 뛰어날 수 있느냐 ?   \n",
       "1  모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...   \n",
       "2                        그러나 이것은 또한 책상도 필요로 하지 않는다 .   \n",
       "3  . 달러하는 이 최첨단 무선 광마우스는 허공에서 팔목 , 팔 , 그외에 어떤 부분이...   \n",
       "4  정보 관리들은 동남 아시아에서의 선박들에 대한 많은 테러 계획들이 실패로 돌아갔음을...   \n",
       "\n",
       "                                              target  \n",
       "0  <start> much of personal computing is about ca...  \n",
       "1  <start> so a mention a few weeks ago about a r...  \n",
       "2  <start> like all optical mice , but it also do...  \n",
       "3  <start> uses gyroscopic sensors to control the...  \n",
       "4  <start> intelligence officials have revealed a...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4ec8f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   30000 non-null  object\n",
      " 1   target  30000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1209a6b",
   "metadata": {},
   "source": [
    "### train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e037edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_test_split(df, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a94ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6e1d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc_f = np.concatenate((x_train,x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e35d0b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(all_doc_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7f21111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['한편 터키는 독일 뒤스브르크에서 열린 평가전에서 핀란드를 으로 제압했다 .',\n",
       "       '<start> meanwhile , turkey continued their preparations for the euro finals with a victory over finland in duisburg , germany . <end>'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_doc_f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2a41ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하지 않는다 .'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['input'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78f281",
   "metadata": {},
   "source": [
    "## pretrained_model_t5_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce627c",
   "metadata": {},
   "source": [
    "### tset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c24c62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "130e898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ko ?.', 'Ko.']\n"
     ]
    }
   ],
   "source": [
    "task_prefix = \"translate Ko to English: \"\n",
    "sentences = [\"너는 누굴까나?.\", \"너는 누구니.\"]\n",
    "\n",
    "inputs = tokenizer([task_prefix + sentence for sentence in sentences], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "output_sequences = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    do_sample=False,  # disable sampling to test if batching affects output\n",
    ")\n",
    "\n",
    "print(tokenizer.batch_decode(output_sequences, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a041b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"KETI-AIR/ke-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0a94b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁모든', '▁광', '마우스', '와', '▁마찬가지', '▁', '로', '▁이', '▁광', '마우스', '도', '▁책상', '▁위에', '▁놓는', '▁마우스', '▁', '패드', '를', '▁필요로', '▁하지', '▁않는다', '▁', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "test_text = x_train['input'][1]\n",
    "test_t5 = tokenizer(test_text).tokens()\n",
    "print(test_t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7ad5c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train) == len(x_train['target']))\n",
    "print(len(x_test) == len(x_test['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18b9a9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a269d640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bf6c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = pd.DataFrame({'input' : x_train['input'], 'target' : x_train['target']}).reset_index(drop=True)\n",
    "test_ = pd.DataFrame({'input' : x_test['input'], 'target' : x_test['target']}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa2f115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = Dataset.from_pandas(train_)\n",
    "test_d = Dataset.from_pandas(test_)\n",
    "\n",
    "# datasetdict형태로 transformation\n",
    "dataset = datasets.DatasetDict({\"train\":train_d,\"test\":test_d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d189258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한편 터키는 독일 뒤스브르크에서 열린 평가전에서 핀란드를 으로 제압했다 .</td>\n",
       "      <td>&lt;start&gt; meanwhile , turkey continued their pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이들은 소속당의 열성 지지자뿐만아니라 부동층 및 상대정당의 당원까지 공략하고 나섰다 .</td>\n",
       "      <td>&lt;start&gt; they are portraying themselves as unit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그가 받은 처벌이 어떠한 것인지에 대해서는 알려지지 않았다 .</td>\n",
       "      <td>&lt;start&gt; the marine corps would not specify wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>로딕은 처음부터 서비스가 잘 들어갔다 며 서비스가 위력적이어서 승리할 수 있었다 고...</td>\n",
       "      <td>&lt;start&gt; one ace was . mph , breaking the dubai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>수도 전역의 여러 개의 붕괴된 건물 속에 많은 사람들이 실종된 것으로 보도되면서 사...</td>\n",
       "      <td>&lt;start&gt; local media reports said one man died ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>로열 아윈 병원의 렌 노타로스 박사는 호주 방송과의 인터뷰에서 대통령의 몸에 박힌 ...</td>\n",
       "      <td>&lt;start&gt; surgeons operated on ramos horta for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>노무현 대통령은 일 KTV 특집 인터뷰에서 제 차 남북정상회담을 언급하며 김정일 국...</td>\n",
       "      <td>&lt;start&gt; north korean leader kim jong il is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>년 LZ 힌데브르크가 뉴저지에서 이륙 직전 추락해 화재로 타버렸을 때 라디오 저널리...</td>\n",
       "      <td>&lt;start&gt; london , england cnn oh , the humanity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>인도 헌법상 세습적 계급 제도를 근거로 한 신분 차별은 위법이며 대도시에선 이러한 ...</td>\n",
       "      <td>&lt;start&gt; india s constitution outlaws caste bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>그는 지난달 일 동티모르의 수도 딜리에서 반군이 쏜 총에 맞고 긴급 수술 후 이곳 ...</td>\n",
       "      <td>&lt;start&gt; president jose ramos horta , , looked ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input  \\\n",
       "0              한편 터키는 독일 뒤스브르크에서 열린 평가전에서 핀란드를 으로 제압했다 .   \n",
       "1       이들은 소속당의 열성 지지자뿐만아니라 부동층 및 상대정당의 당원까지 공략하고 나섰다 .   \n",
       "2                     그가 받은 처벌이 어떠한 것인지에 대해서는 알려지지 않았다 .   \n",
       "3      로딕은 처음부터 서비스가 잘 들어갔다 며 서비스가 위력적이어서 승리할 수 있었다 고...   \n",
       "4      수도 전역의 여러 개의 붕괴된 건물 속에 많은 사람들이 실종된 것으로 보도되면서 사...   \n",
       "...                                                  ...   \n",
       "23995  로열 아윈 병원의 렌 노타로스 박사는 호주 방송과의 인터뷰에서 대통령의 몸에 박힌 ...   \n",
       "23996  노무현 대통령은 일 KTV 특집 인터뷰에서 제 차 남북정상회담을 언급하며 김정일 국...   \n",
       "23997  년 LZ 힌데브르크가 뉴저지에서 이륙 직전 추락해 화재로 타버렸을 때 라디오 저널리...   \n",
       "23998  인도 헌법상 세습적 계급 제도를 근거로 한 신분 차별은 위법이며 대도시에선 이러한 ...   \n",
       "23999  그는 지난달 일 동티모르의 수도 딜리에서 반군이 쏜 총에 맞고 긴급 수술 후 이곳 ...   \n",
       "\n",
       "                                                  target  \n",
       "0      <start> meanwhile , turkey continued their pre...  \n",
       "1      <start> they are portraying themselves as unit...  \n",
       "2      <start> the marine corps would not specify wha...  \n",
       "3      <start> one ace was . mph , breaking the dubai...  \n",
       "4      <start> local media reports said one man died ...  \n",
       "...                                                  ...  \n",
       "23995  <start> surgeons operated on ramos horta for t...  \n",
       "23996  <start> north korean leader kim jong il is the...  \n",
       "23997  <start> london , england cnn oh , the humanity...  \n",
       "23998  <start> india s constitution outlaws caste bas...  \n",
       "23999  <start> president jose ramos horta , , looked ...  \n",
       "\n",
       "[24000 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 값 최종 확인\n",
    "dataset.set_format(type='pandas')\n",
    "df = dataset['train'][:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cebd302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩하여 최종 데이터 dict 저장\n",
    "dataset.set_format(type=None)\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['input'], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd32af31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9958eb25ee4d4f329029b42aa6a5c39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d871457b014026a06fc2e5925b5ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_encoded = dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83a32f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['attention_mask', 'input', 'input_ids', 'target'], 'test': ['attention_mask', 'input', 'input_ids', 'target']}\n",
      "['attention_mask', 'input', 'input_ids', 'target']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_encoded.column_names)\n",
    "print(dataset_encoded[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b29d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': '<start> meanwhile , turkey continued their preparations for the euro finals with a victory over finland in duisburg , germany . <end>', 'input_ids': [228, 6211, 12, 1511, 261, 296, 43125, 1082, 37, 440, 42821, 22635, 21, 7, 45, 37920, 7, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input': '한편 터키는 독일 뒤스브르크에서 열린 평가전에서 핀란드를 으로 제압했다 .', 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_encoded[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "004d465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator =  DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee74e50",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6382468",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2\n",
    "num_epochs = 5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03c8b6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KETI-AIR/ke-t5-small were not used when initializing T5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"KETI-AIR/ke-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53d9dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1251cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModel.from_pretrained(\"KETI-AIR/ke-t5-small\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93315812",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = 'data_test',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    save_steps=1e6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    disable_tqdm=True,\n",
    "    load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c80a8744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/KETI-AIR/ke-t5-small/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/a240b555451a28d400c0fcd042656bc28d18c553be5503a17a5fff9ab86ecf1b.cfa5a0bf5803bcceef6e8ff70f41932d7d5eb3b077c6885fadf7e912703f33e9\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"hf/ke-t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 1024,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 8,\n",
      "  \"num_heads\": 6,\n",
      "  \"num_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/KETI-AIR/ke-t5-small/resolve/main/pytorch_model.bin from cache at /aiffel/.cache/huggingface/transformers/b507b951b740a5181bad562d35074d8ca263278c343090e1a5ebf6e19c4576d6.9718d7ed3498702cfca52320624732deeacc9d0f4876059768b09881e73b561d\n",
      "Some weights of the model checkpoint at KETI-AIR/ke-t5-small were not used when initializing T5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of T5Model were initialized from the model checkpoint at KETI-AIR/ke-t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5Model for predictions without further training.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_343/2369072691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer = Trainer(model_init=model_init,\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mdata_collator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_collator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_model_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`Trainer` requires either a `model` or `model_init` argument\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcall_model_init\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mmodel_init_argcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_init_argcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_init_argcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_343/1646331626.py\u001b[0m in \u001b[0;36mmodel_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KETI-AIR/ke-t5-small\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model_init=model_init,\n",
    "                  args=args,\n",
    "                  data_collator=data_collator,\n",
    "                  train_dataset=dataset_encoded[\"train\"],\n",
    "                  eval_dataset=dataset_encoded[\"test\"],\n",
    "                  tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d4a792",
   "metadata": {},
   "source": [
    "### pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bdeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")\n",
    "\n",
    "test = \"안녕 내이름은 곱등이. 곱등 곱등\"\n",
    "sent_tokenize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c81a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset['train'][\"input\"][1]\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c36262",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"안녕하세요\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"translation_ko_to_en\", model=\"KETI-AIR/ke-t5-large\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b74f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_out = pipe(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40305cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"translation_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec723099",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a2ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
